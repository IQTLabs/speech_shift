{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-12 14:10:23 | ERROR | fbprophet.plot | Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import aggregators\n",
    "import embeddors\n",
    "import data_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from alibi_detect.cd import MMDDrift\n",
    "from alibi_detect.cd.preprocess import UAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this component to the root of the VOiCES dataset\n",
    "DATASET_ROOT = '/Users/jberkowitz/Datasets/VOiCES_devkit'\n",
    "# Convenience function to add root to data path\n",
    "add_root = lambda x: os.path.join(DATASET_ROOT,x)"
   ]
  },
  {
   "source": [
    "First we will load the dataframe for the `training` slice of VOiCES, and perform a few cleaning operations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index  chapter  degrees distractor  \\\n",
       "0      0     9960       60       musi   \n",
       "1      1     9960       60       musi   \n",
       "\n",
       "                                            filename gender  mic  \\\n",
       "0  distant-16k/speech/train/rm1/musi/sp0083/Lab41...      F    1   \n",
       "1  distant-16k/speech/train/rm1/musi/sp0083/Lab41...      F    5   \n",
       "\n",
       "                                          query_name room  segment  \\\n",
       "0  Lab41-SRI-VOiCES-rm1-musi-sp0083-ch009960-sg00...  rm1       42   \n",
       "1  Lab41-SRI-VOiCES-rm1-musi-sp0083-ch009960-sg00...  rm1       42   \n",
       "\n",
       "                                              source  speaker  \\\n",
       "0  source-16k/train/sp0083/Lab41-SRI-VOiCES-src-s...       83   \n",
       "1  source-16k/train/sp0083/Lab41-SRI-VOiCES-src-s...       83   \n",
       "\n",
       "                                          transcript  noisy_length  noisy_sr  \\\n",
       "0  the horrible glowing tool disappeared into the...        258880     16000   \n",
       "1  the horrible glowing tool disappeared into the...        258880     16000   \n",
       "\n",
       "   noisy_time  source_length  source_sr  source_time  \n",
       "0       16.18         258880      16000        16.18  \n",
       "1       16.18         258880      16000        16.18  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>chapter</th>\n      <th>degrees</th>\n      <th>distractor</th>\n      <th>filename</th>\n      <th>gender</th>\n      <th>mic</th>\n      <th>query_name</th>\n      <th>room</th>\n      <th>segment</th>\n      <th>source</th>\n      <th>speaker</th>\n      <th>transcript</th>\n      <th>noisy_length</th>\n      <th>noisy_sr</th>\n      <th>noisy_time</th>\n      <th>source_length</th>\n      <th>source_sr</th>\n      <th>source_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>9960</td>\n      <td>60</td>\n      <td>musi</td>\n      <td>distant-16k/speech/train/rm1/musi/sp0083/Lab41...</td>\n      <td>F</td>\n      <td>1</td>\n      <td>Lab41-SRI-VOiCES-rm1-musi-sp0083-ch009960-sg00...</td>\n      <td>rm1</td>\n      <td>42</td>\n      <td>source-16k/train/sp0083/Lab41-SRI-VOiCES-src-s...</td>\n      <td>83</td>\n      <td>the horrible glowing tool disappeared into the...</td>\n      <td>258880</td>\n      <td>16000</td>\n      <td>16.18</td>\n      <td>258880</td>\n      <td>16000</td>\n      <td>16.18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>9960</td>\n      <td>60</td>\n      <td>musi</td>\n      <td>distant-16k/speech/train/rm1/musi/sp0083/Lab41...</td>\n      <td>F</td>\n      <td>5</td>\n      <td>Lab41-SRI-VOiCES-rm1-musi-sp0083-ch009960-sg00...</td>\n      <td>rm1</td>\n      <td>42</td>\n      <td>source-16k/train/sp0083/Lab41-SRI-VOiCES-src-s...</td>\n      <td>83</td>\n      <td>the horrible glowing tool disappeared into the...</td>\n      <td>258880</td>\n      <td>16000</td>\n      <td>16.18</td>\n      <td>258880</td>\n      <td>16000</td>\n      <td>16.18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "full_index_df = pd.read_csv(add_root('references/train_index.csv'))\n",
    "# Drop recordings that don't match in length to source audio\n",
    "trimmed_index = full_index_df[full_index_df['noisy_length']==full_index_df['source_length']]\n",
    "trimmed_index.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "len(trimmed_index[trimmed_index['distractor']=='babb'])"
   ]
  },
  {
   "source": [
    "Next we initialize the embeddors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-12 14:12:29 | INFO | fairseq.models.wav2vec.wav2vec | Wav2VecModel(\n",
      "  (feature_extractor): ConvFeatureExtractionModel(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(8,), stride=(4,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): Dropout(p=0.0, inplace=False)\n",
      "        (2): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_aggregator): ConvAggegator(\n",
      "    (conv_layers): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): ReplicationPad1d((1, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(2,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ReplicationPad1d((2, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(3,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ReplicationPad1d((3, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(4,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): ReplicationPad1d((4, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): ReplicationPad1d((5, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(6,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): ReplicationPad1d((6, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): ReplicationPad1d((7, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(8,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): ReplicationPad1d((8, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(9,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (8): Sequential(\n",
      "        (0): ReplicationPad1d((9, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(10,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (9): Sequential(\n",
      "        (0): ReplicationPad1d((10, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(11,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (10): Sequential(\n",
      "        (0): ReplicationPad1d((11, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(12,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (11): Sequential(\n",
      "        (0): ReplicationPad1d((12, 0))\n",
      "        (1): Conv1d(512, 512, kernel_size=(13,), stride=(1,))\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Fp32GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (residual_proj): ModuleList(\n",
      "      (0): None\n",
      "      (1): None\n",
      "      (2): None\n",
      "      (3): None\n",
      "      (4): None\n",
      "      (5): None\n",
      "      (6): None\n",
      "      (7): None\n",
      "      (8): None\n",
      "      (9): None\n",
      "      (10): None\n",
      "      (11): None\n",
      "    )\n",
      "  )\n",
      "  (wav2vec_predictions): Wav2VecPredictionsModel(\n",
      "    (project_to_steps): ConvTranspose2d(512, 512, kernel_size=(1, 12), stride=(1, 1))\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (dropout_feats): Dropout(p=0.0, inplace=False)\n",
      "  (dropout_agg): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "2020-12-12 14:12:29 | INFO | absl | Downloading TF-Hub Module 'https://tfhub.dev/google/nonsemantic-speech-benchmark/trill-distilled/2'.\n",
      "2020-12-12 14:12:46 | INFO | absl | Downloading https://tfhub.dev/google/nonsemantic-speech-benchmark/trill-distilled/2: 100.50MB\n",
      "2020-12-12 14:13:01 | INFO | absl | Downloaded https://tfhub.dev/google/nonsemantic-speech-benchmark/trill-distilled/2, Total size: 198.74MB\n",
      "2020-12-12 14:13:01 | INFO | absl | Downloaded TF-Hub Module 'https://tfhub.dev/google/nonsemantic-speech-benchmark/trill-distilled/2'.\n"
     ]
    }
   ],
   "source": [
    "w2v = embeddors.Wav2VecEmbeddor(weight_path='models/wav2vec_large.pt')\n",
    "trill=embeddors.TrillEmbeddor()"
   ]
  },
  {
   "source": [
    "Initialize the aggregators"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ag = aggregators.MeanAggregator()\n",
    "pca_ag = aggregators.PCAAggregator()"
   ]
  },
  {
   "source": [
    "We will also use untrained autoencoders (UAE) to do some preliminary dimension reduction, as in [Failing Loudly: An Empirical Study of Methods for Detecting Dataset Shift](https://arxiv.org/pdf/1810.11953.pdf).  We will initialize a UAE for both Trill and Wave2Vec embeddings, as they have different dimensionality. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0) # set seed for reproducibility\n",
    "encoding_dim=10 # fixed dimensionality\n",
    "\n",
    "w2v_encoder_net = tf.keras.Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(512,)),\n",
    "        Dense(100,),\n",
    "        Dense(encoding_dim,)\n",
    "    ]\n",
    ")\n",
    "w2v_uae = UAE(w2v_encoder_net)\n",
    "\n",
    "trill_encoder_net = tf.keras.Sequential(\n",
    "    [\n",
    "        InputLayer(input_shape=(2048,)),\n",
    "        Dense(100,),\n",
    "        Dense(encoding_dim,)\n",
    "    ]\n",
    ")\n",
    "trill_uae = UAE(trill_encoder_net)"
   ]
  },
  {
   "source": [
    "Next we will vectorize the data and store it in arrays.  For the clean data and each noise type in VOiCES (none,musi,babb,tele).  We will define a convenience function here to automate the production and storage of all these arrays in dictionaries."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector_dict(file_list):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        file_list - a list of paths to wav files corresponding to all the waveforms to vectorize.\n",
    "    Outputs:\n",
    "        vector_dict - a dictionary with keys w2v_mean,w2v_pca,trill_mean,trill_pca\n",
    "    \"\"\"\n",
    "    waveforms = [librosa.load(file_name,sr=16000)[0] for file_name in file_list]\n",
    "    vector_dict = {}\n",
    "    vector_dict['w2v_mean']=data_utils.pipeline(wav_list=waveforms,embeddor=w2v,aggregator=mean_ag)\n",
    "    vector_dict['w2v_pca']=data_utils.pipeline(wav_list=waveforms,embeddor=w2v,aggregator=pca_ag)\n",
    "    vector_dict['trill_mean']=data_utils.pipeline(wav_list=waveforms,embeddor=trill,aggregator=mean_ag)\n",
    "    vector_dict['trill_pca']=data_utils.pipeline(wav_list=waveforms,embeddor=trill,aggregator=pca_ag)\n",
    "    return vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'w2v_mean': array([[0.0225979 , 0.00788946, 0.04420952, ..., 0.01228718, 0.18554828,\n",
       "         0.12250672],\n",
       "        [0.0225979 , 0.00788946, 0.04420952, ..., 0.01228718, 0.18554828,\n",
       "         0.12250672],\n",
       "        [0.03045051, 0.01346586, 0.05660842, ..., 0.01263731, 0.16521999,\n",
       "         0.2128439 ],\n",
       "        [0.03045051, 0.01346586, 0.05660842, ..., 0.01263731, 0.16521999,\n",
       "         0.2128439 ],\n",
       "        [0.03135986, 0.01382883, 0.11795536, ..., 0.01408581, 0.23116378,\n",
       "         0.16410196]], dtype=float32),\n",
       " 'w2v_pca': array([[-2.7104260e-03, -9.5924057e-05, -1.1925279e-02, ...,\n",
       "          3.8271321e-03, -6.2693387e-02,  1.2496358e-02],\n",
       "        [-2.7104104e-03, -9.5921598e-05, -1.1925279e-02, ...,\n",
       "          3.8271321e-03, -6.2693425e-02,  1.2496394e-02],\n",
       "        [-1.8501817e-03, -2.1425122e-03, -1.9867809e-02, ...,\n",
       "          3.0232358e-03, -4.2727299e-02, -3.7932701e-03],\n",
       "        [-1.8502675e-03, -2.1425067e-03, -1.9867813e-02, ...,\n",
       "          3.0232349e-03, -4.2727273e-02, -3.7933113e-03],\n",
       "        [-6.7147339e-04, -7.9072182e-05,  2.5413656e-03, ...,\n",
       "          4.3201069e-03, -9.6267864e-02,  1.4855072e-02]], dtype=float32),\n",
       " 'trill_mean': array([[0.1162793 , 0.3375367 , 0.12931669, ..., 0.10944552, 0.18296733,\n",
       "         0.12042784],\n",
       "        [0.1162793 , 0.3375367 , 0.12931669, ..., 0.10944552, 0.18296733,\n",
       "         0.12042784],\n",
       "        [0.13542715, 0.2226117 , 0.19049424, ..., 0.14772846, 0.16402808,\n",
       "         0.16426493],\n",
       "        [0.13542715, 0.2226117 , 0.19049424, ..., 0.14772846, 0.16402808,\n",
       "         0.16426493],\n",
       "        [0.11522291, 0.13096052, 0.21626171, ..., 0.14555219, 0.18941714,\n",
       "         0.15667403]], dtype=float32),\n",
       " 'trill_pca': array([[-0.00909054,  0.01543966, -0.01314178, ..., -0.00828996,\n",
       "         -0.01732181, -0.00807088],\n",
       "        [-0.00909065,  0.01543966, -0.01314178, ..., -0.00828996,\n",
       "         -0.01732181, -0.00807088],\n",
       "        [-0.01837042, -0.01416387, -0.01640537, ...,  0.01094798,\n",
       "          0.01292113,  0.0142788 ],\n",
       "        [-0.01787722, -0.01400685, -0.01623165, ...,  0.01108942,\n",
       "          0.01297632,  0.01416036],\n",
       "        [-0.01271679,  0.00946162, -0.01759773, ..., -0.01782107,\n",
       "         -0.00558473, -0.0137487 ]], dtype=float32)}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "source_vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}